# é«˜æ€§èƒ½æ¨ç†æœåŠ¡å™¨

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

[English](README.md) | [ä¸­æ–‡](README_CN.md)

ä¸€ä¸ªä½¿ç”¨äºŒè¿›åˆ¶åè®®ï¼ˆPickleï¼‰å®ç°çš„é«˜æ€§èƒ½æ¨ç†æœåŠ¡å™¨ï¼Œç”¨äºå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´çš„å¿«é€Ÿæ•°æ®ä¼ è¾“ã€‚é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹æ¨ç†è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå»¶è¿Ÿæœ€å°åŒ–ã€‚


## âœ¨ ç‰¹æ€§

- **äºŒè¿›åˆ¶åè®®**ï¼šä½¿ç”¨ Pickle Protocol 5 é«˜æ•ˆåºåˆ—åŒ– Python å¯¹è±¡å’Œ numpy æ•°ç»„
- **é›¶æ‹·è´ä¼˜åŒ–**ï¼šæœ€å°åŒ–ä¼ è¾“è¿‡ç¨‹ä¸­çš„æ•°æ®æ‹·è´å¼€é”€
- **ç®€å• API**ï¼šåŸºäº Flask çš„æ˜“ç”¨ REST API
- **çµæ´»æ€§å¼º**ï¼šæ”¯æŒä»»æ„ Python å¯¹è±¡åºåˆ—åŒ–ï¼Œä¸é™äºç‰¹å®šæ•°æ®ç±»å‹
- **çƒ­æ›´æ–°æ¨¡å‹**ï¼šæ”¯æŒåŠ¨æ€æ›´æ–°æ¨¡å‹ï¼Œæ— éœ€é‡å¯æœåŠ¡å™¨
- **å¥å£®çš„å®¢æˆ·ç«¯**ï¼šè‡ªåŠ¨é‡è¯•é€»è¾‘ï¼Œå¯é…ç½®è¶…æ—¶
- **å•çº¿ç¨‹**ï¼šç¡®å®šæ€§çš„é¡ºåºå¤„ç†ï¼Œä¿è¯ç»“æœå¯å¤ç°

## ğŸ—ï¸ æ¶æ„

```
å®¢æˆ·ç«¯                          æœåŠ¡å™¨
  |                               |
  |  1. åºåˆ—åŒ–æ•°æ® (Pickle)        |
  |------------------------------>|
  |                               | 2. ååºåˆ—åŒ–
  |                               | 3. æ¨¡å‹æ¨ç†
  |                               | 4. åºåˆ—åŒ–ç»“æœ
  |<------------------------------|
  |  5. ååºåˆ—åŒ–ç»“æœ               |
```

**ä¸ºä»€ä¹ˆä½¿ç”¨äºŒè¿›åˆ¶åè®®ï¼Ÿ**
- å¯¹äº numpy æ•°ç»„ï¼Œæ¯” JSON å¿« 10-50 å€
- æ”¯æŒä»»æ„ Python å¯¹è±¡
- Protocol 5 å¯¹å¤§å‹æ•°ç»„å®ç°é›¶æ‹·è´
- CPU å¼€é”€æœ€å°

## ğŸ“¦ å®‰è£…

### ä¾èµ–è¦æ±‚

- Python >= 3.8
- PyTorch >= 1.10
- Flask >= 2.0
- NumPy >= 1.20
- requests >= 2.25

### ä»æºç å®‰è£…

```bash
git clone https://github.com/yourusername/Server_OpenSource.git
cd Server_OpenSource
pip install -r requirements.txt
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨æœåŠ¡å™¨

**æ–¹å¼ Aï¼šä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬**

```bash
./start_server.sh
```

**æ–¹å¼ Bï¼šæ‰‹åŠ¨å¯åŠ¨**

```bash
python server.py --model-path /path/to/your/model --device cuda:0 --port 50000
```

å‚æ•°è¯´æ˜ï¼š
- `--model-path`ï¼šæ¨¡å‹ç›®å½•è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--device`ï¼šæ¨ç†è®¾å¤‡ï¼ˆé»˜è®¤ï¼š`cpu`ï¼‰
- `--port`ï¼šæœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤ï¼š`50000`ï¼‰
- `--host`ï¼šæœåŠ¡å™¨ä¸»æœºï¼ˆé»˜è®¤ï¼š`127.0.0.1`ï¼‰

### 2. å‘é€æ¨ç†è¯·æ±‚

```python
from request_tools import send_inference_request
import numpy as np

# å‡†å¤‡æ•°æ®
data = {
    "instruction": "ä½ çš„æŒ‡ä»¤",
    "state": np.array([0.1, 0.2, 0.3], dtype=np.float32),
    "image": np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),
}

# å‘é€è¯·æ±‚
result = send_inference_request(
    data_dict=data,
    url='http://127.0.0.1:50000/infer',
    timeout=10
)

print(result)
```

### 3. æµ‹è¯•æœåŠ¡å™¨

```bash
# è¿è¡ŒåŸºç¡€æµ‹è¯•
python test_server.py

# è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•
python benchmark.py
```

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€æ¨ç†

```python
from request_tools import send_inference_request
import numpy as np

data = {
    "instruction": "æ‹¿èµ·çº¢è‰²æ¯å­",
    "state": np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype=np.float32),
    "image": np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),
}

result = send_inference_request(data, url='http://127.0.0.1:50000/infer')
print(f"çŠ¶æ€: {result['status']}")
print(f"è¾“å‡º: {result['output']}")
```

### æ‰¹é‡å¤„ç†

```python
import numpy as np
from request_tools import send_inference_request

# é¡ºåºå¤„ç†å¤šä¸ªæ ·æœ¬
for i in range(10):
    data = {
        "instruction": f"ä»»åŠ¡ {i}",
        "state": np.random.randn(6).astype(np.float32),
        "image": np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),
    }
    result = send_inference_request(data, url='http://127.0.0.1:50000/infer')
    print(f"ä»»åŠ¡ {i}: {result['status']}")
```

### é”™è¯¯å¤„ç†

```python
from request_tools import send_inference_request

try:
    result = send_inference_request(
        data_dict=data,
        url='http://127.0.0.1:50000/infer',
        timeout=10,
        max_retries=3,
        retry_delay=1.0
    )
except RuntimeError as e:
    print(f"è¯·æ±‚å¤±è´¥: {e}")
```

### æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ [example_usage.py](example_usage.py) è·å–æ›´å¤šç»¼åˆç¤ºä¾‹ã€‚

## ğŸ“– API å‚è€ƒ

### POST /infer

æ¨ç†æ¥å£ã€‚

**è¯·æ±‚ï¼š**
- Content-Type: `application/octet-stream`
- Body: Pickle åºåˆ—åŒ–çš„äºŒè¿›åˆ¶æ•°æ®

**å“åº”ï¼š**
- Content-Type: `application/octet-stream`
- Body: åŒ…å«æ¨ç†ç»“æœçš„äºŒè¿›åˆ¶æ•°æ®

**å“åº”ç¤ºä¾‹ï¼š**
```python
{
    "status": "ok",
    "output": numpy.ndarray  # æ¨¡å‹è¾“å‡º
}
```

**é”™è¯¯å“åº”ï¼š**
```python
{
    "status": "error",
    "message": "é”™è¯¯æè¿°"
}
```

### POST /update_model

åŠ¨æ€æ›´æ–°æ¨¡å‹ï¼Œæ— éœ€é‡å¯æœåŠ¡å™¨ã€‚

**è¯·æ±‚ï¼š**
- Content-Type: `multipart/form-data`
- File: åŒ…å«æ¨¡å‹æ–‡ä»¶çš„ `.tar` å‹ç¼©åŒ…
- Form data: `device`ï¼ˆå¯é€‰ï¼Œå¦‚ "cuda:0"ã€"cpu"ï¼‰

**å“åº”ï¼š**
```json
{
    "message": "Policy updated successfully"
}
```

**ç¤ºä¾‹ï¼š**
```python
import requests

with open('model.tar', 'rb') as f:
    files = {'file': ('model.tar', f, 'application/x-tar')}
    data = {'device': 'cuda:0'}
    response = requests.post('http://127.0.0.1:50000/update_model',
                            files=files, data=data)
print(response.json())
```

## âš¡ æ€§èƒ½

### åŸºå‡†æµ‹è¯•ç»“æœ

æµ‹è¯•ç¯å¢ƒï¼šIntel i7-10700K, 32GB RAM, RTX 3080

| æ•°æ®å¤§å° | åºåˆ—åŒ– | ååºåˆ—åŒ– | ç«¯åˆ°ç«¯å»¶è¿Ÿ |
|---------|--------|---------|-----------|
| å° (VGA) | 2.5 ms | 1.8 ms | 15 ms |
| ä¸­ (HD) | 5.2 ms | 3.6 ms | 22 ms |
| å¤§ (Full HD) | 12.8 ms | 8.4 ms | 35 ms |

**ååé‡ï¼š** åºåˆ—åŒ–çº¦ 250 MB/sï¼Œç½‘ç»œä¼ è¾“çº¦ 180 MB/s

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨ C-contiguous æ•°ç»„**ï¼šç¡®ä¿ numpy æ•°ç»„æ˜¯ C-contiguous çš„
2. **ä½¿ç”¨åˆé€‚çš„æ•°æ®ç±»å‹**ï¼šå°½å¯èƒ½ä½¿ç”¨ `float32` è€Œä¸æ˜¯ `float64`
3. **æ‰¹å¤„ç†**ï¼šå¦‚æœæ¨¡å‹æ”¯æŒï¼Œåœ¨ä¸€ä¸ªè¯·æ±‚ä¸­å‘é€å¤šä¸ªæ ·æœ¬
4. **å›ºå®šå†…å­˜**ï¼šå¯ç”¨å›ºå®šå†…å­˜ä»¥åŠ é€Ÿ CPU-GPU ä¼ è¾“ï¼ˆå‚è§ [DEVELOPMENT_CN.md](DEVELOPMENT_CN.md)ï¼‰

è¿è¡Œä½ è‡ªå·±çš„åŸºå‡†æµ‹è¯•ï¼š
```bash
python benchmark.py
```

## ğŸ› ï¸ å¼€å‘

### é¡¹ç›®ç»“æ„

```
Server_OpenSource/
â”œâ”€â”€ README.md              # è‹±æ–‡æ–‡æ¡£
â”œâ”€â”€ README_CN.md           # ä¸­æ–‡æ–‡æ¡£
â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â”œâ”€â”€ server.py             # æœåŠ¡å™¨ä¸»å®ç°
â”œâ”€â”€ request_tools.py      # å®¢æˆ·ç«¯è¯·æ±‚å·¥å…·
â”œâ”€â”€ binary_protocol.py    # åºåˆ—åŒ–/ååºåˆ—åŒ–
â”œâ”€â”€ tools.py              # è¾…åŠ©å‡½æ•°
â”œâ”€â”€ example_usage.py      # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ test_server.py        # æœåŠ¡å™¨æµ‹è¯•
â”œâ”€â”€ benchmark.py          # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”œâ”€â”€ start_server.sh       # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ DEVELOPMENT.md        # å¼€å‘æŒ‡å—
â”œâ”€â”€ DEVELOPMENT_CN.md     # å¼€å‘æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰
â”œâ”€â”€ CONTRIBUTING.md       # è´¡çŒ®æŒ‡å—
â”œâ”€â”€ CHANGELOG.md          # ç‰ˆæœ¬å†å²
â””â”€â”€ LICENSE               # Apache 2.0 è®¸å¯è¯
```

### è‡ªå®šä¹‰

æŸ¥çœ‹ [DEVELOPMENT_CN.md](DEVELOPMENT_CN.md) è·å–è¯¦ç»†è¯´æ˜ï¼š
- é›†æˆè‡ªå·±çš„æ¨¡å‹
- æ·»åŠ è‡ªå®šä¹‰ç«¯ç‚¹
- æ€§èƒ½ä¼˜åŒ–
- æµ‹è¯•å’Œéƒ¨ç½²

### è¿è¡Œæµ‹è¯•

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_server.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python benchmark.py

# è¿è¡Œç¤ºä¾‹
python example_usage.py
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è´¡çŒ®æŒ‡å—ã€‚

### è´¡çŒ®æ–¹å‘

- æ·»åŠ æ›´å…¨é¢çš„æµ‹è¯•
- æ”¹è¿›é”™è¯¯å¤„ç†
- æ·»åŠ æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ”¹è¿›æ–‡æ¡£
- æ·»åŠ  gRPC åè®®æ”¯æŒ
- å®ç°è¯·æ±‚æ‰¹å¤„ç†
- æ·»åŠ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“® è”ç³»æ–¹å¼

- é—®é¢˜åé¦ˆï¼š[GitHub Issues](https://github.com/yourusername/Server_OpenSource/issues)
- è®¨è®ºï¼š[GitHub Discussions](https://github.com/yourusername/Server_OpenSource/discussions)

## ğŸ™ è‡´è°¢

- åŸºäº [Flask](https://flask.palletsprojects.com/) æ„å»º
- ç”± [PyTorch](https://pytorch.org/) é©±åŠ¨
- ä½¿ç”¨ Python [Pickle](https://docs.python.org/3/library/pickle.html) åºåˆ—åŒ–

## ğŸ“Š å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{fast_inference_server,
  title = {Fast Inference Server: High-Performance Binary Protocol for Deep Learning Inference},
  author = {Your Name},
  year = {2025},
  url = {https://github.com/yourusername/Server_OpenSource}
}
```

---

**å¦‚æœè§‰å¾—æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Star â­ï¼**
