# å¿«é€Ÿæ¨ç†æœåŠ¡å™¨ - é¡¹ç›®æ€»ç»“

## ğŸ“¦ è¿™æ˜¯ä»€ä¹ˆé¡¹ç›®ï¼Ÿ

å¿«é€Ÿæ¨ç†æœåŠ¡å™¨æ˜¯ä¸€ä¸ªä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡çš„é«˜æ€§èƒ½æ¨ç†æœåŠ¡å™¨ã€‚å®ƒä½¿ç”¨äºŒè¿›åˆ¶åè®®ï¼ˆPickleï¼‰åœ¨å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´è¿›è¡Œé«˜æ•ˆçš„æ•°æ®ä¼ è¾“ï¼Œå¯¹äº numpy æ•°ç»„ï¼Œåºåˆ—åŒ–é€Ÿåº¦æ¯” JSON å¿« 10-50 å€ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

1. **äºŒè¿›åˆ¶åè®®**ï¼šä½¿ç”¨ Pickle Protocol 5 é«˜æ•ˆåºåˆ—åŒ–
2. **å•çº¿ç¨‹**ï¼šç¡®å®šæ€§çš„é¡ºåºå¤„ç†
3. **çƒ­æ›´æ–°æ¨¡å‹**ï¼šæ— éœ€é‡å¯æœåŠ¡å™¨å³å¯æ›´æ–°æ¨¡å‹
4. **å¥å£®çš„å®¢æˆ·ç«¯**ï¼šè‡ªåŠ¨é‡è¯•ï¼Œå¯é…ç½®è¶…æ—¶
5. **çµæ´»æ€§å¼º**ï¼šæ”¯æŒä»»æ„ Python å¯¹è±¡ï¼Œä¸é™äºç‰¹å®šç±»å‹

## ğŸ“ é¡¹ç›®ç»“æ„

```
Server_OpenSource/
â”œâ”€â”€ æ ¸å¿ƒæ–‡ä»¶
â”‚   â”œâ”€â”€ server.py              # æœåŠ¡å™¨ä¸»å®ç°
â”‚   â”œâ”€â”€ request_tools.py       # å®¢æˆ·ç«¯å·¥å…·
â”‚   â”œâ”€â”€ binary_protocol.py     # åºåˆ—åŒ–é€»è¾‘
â”‚   â””â”€â”€ tools.py               # è¾…åŠ©å‡½æ•°
â”‚
â”œâ”€â”€ æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md              # è‹±æ–‡æ–‡æ¡£
â”‚   â”œâ”€â”€ README_CN.md           # ä¸­æ–‡æ–‡æ¡£
â”‚   â”œâ”€â”€ DEVELOPMENT.md         # å¼€å‘æŒ‡å—ï¼ˆè‹±æ–‡ï¼‰
â”‚   â”œâ”€â”€ DEVELOPMENT_CN.md      # å¼€å‘æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰
â”‚   â”œâ”€â”€ CONTRIBUTING.md        # è´¡çŒ®æŒ‡å—
â”‚   â””â”€â”€ CHANGELOG.md           # ç‰ˆæœ¬å†å²
â”‚
â”œâ”€â”€ ç¤ºä¾‹å’Œæµ‹è¯•
â”‚   â”œâ”€â”€ example_usage.py       # ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ test_server.py         # æœåŠ¡å™¨æµ‹è¯•
â”‚   â””â”€â”€ benchmark.py           # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚
â”œâ”€â”€ éƒ¨ç½²
â”‚   â”œâ”€â”€ Dockerfile             # Docker é•œåƒ
â”‚   â”œâ”€â”€ docker-compose.yml     # Docker Compose é…ç½®
â”‚   â”œâ”€â”€ start_server.sh        # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ requirements.txt       # Python ä¾èµ–
â”‚
â””â”€â”€ é…ç½®
    â”œâ”€â”€ setup.py               # åŒ…è®¾ç½®
    â”œâ”€â”€ MANIFEST.in            # åŒ…æ¸…å•
    â”œâ”€â”€ .gitignore             # Git å¿½ç•¥è§„åˆ™
    â””â”€â”€ LICENSE                # Apache 2.0 è®¸å¯è¯
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1ï¼šç›´æ¥è¿è¡Œ
```bash
python server.py --model-path /path/to/model --device cuda:0 --port 50000
```

### æ–¹å¼ 2ï¼šä½¿ç”¨è„šæœ¬
```bash
./start_server.sh
```

### æ–¹å¼ 3ï¼šDocker
```bash
docker-compose up -d
```

## ğŸ“Š æ€§èƒ½

- **åºåˆ—åŒ–**ï¼šçº¦ 250 MB/s
- **ç½‘ç»œä¼ è¾“**ï¼šçº¦ 180 MB/s
- **å»¶è¿Ÿ**ï¼š15-35msï¼ˆå–å†³äºæ•°æ®å¤§å°ï¼‰

## ğŸ”§ è‡ªå®šä¹‰

### é›†æˆä½ çš„æ¨¡å‹

ç¼–è¾‘ `server.py`ï¼š

```python
def load_model(model_path: str, device: torch.device):
    # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹åŠ è½½é€»è¾‘
    model = YourModel.from_pretrained(model_path)
    return model.to(device).eval()

def model_inference(obs: dict) -> np.ndarray:
    # æ›¿æ¢ä¸ºä½ çš„æ¨ç†é€»è¾‘
    with torch.inference_mode():
        output = model(obs)
    return output.detach().cpu().numpy()
```

### æ·»åŠ è‡ªå®šä¹‰ç«¯ç‚¹

```python
@app.route('/your_endpoint', methods=['POST'])
def your_endpoint():
    # ä½ çš„è‡ªå®šä¹‰é€»è¾‘
    return Response(...)
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

```python
from request_tools import send_inference_request
import numpy as np

data = {
    "instruction": "æ‹¿èµ·æ¯å­",
    "state": np.array([0.1, 0.2, 0.3], dtype=np.float32),
    "image": np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),
}

result = send_inference_request(
    data_dict=data,
    url='http://127.0.0.1:50000/infer',
    timeout=10
)

print(result)
```

## ğŸ§ª æµ‹è¯•

```bash
# åŸºç¡€æµ‹è¯•
python test_server.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python benchmark.py

# è¿è¡Œç¤ºä¾‹
python example_usage.py
```

## ğŸ³ Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t inference-server .

# è¿è¡Œå®¹å™¨
docker run -p 50000:50000 -v /path/to/models:/models inference-server

# æˆ–ä½¿ç”¨ docker-compose
docker-compose up -d
```

## ğŸ“š æ–‡æ¡£

- **README_CN.md**ï¼šé¡¹ç›®æ¦‚è§ˆå’Œå¿«é€Ÿå¼€å§‹
- **DEVELOPMENT_CN.md**ï¼šè¯¦ç»†å¼€å‘æŒ‡å—
- **CONTRIBUTING.md**ï¼šå¦‚ä½•è´¡çŒ®
- **API å‚è€ƒ**ï¼šæŸ¥çœ‹ README_CN.md ä¸­çš„ API æ–‡æ¡£

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è´¡çŒ®æŒ‡å—ã€‚

### ä¼˜å…ˆæ–¹å‘
- [ ] æ·»åŠ å…¨é¢çš„æµ‹è¯•
- [ ] æ”¹è¿›é”™è¯¯å¤„ç†
- [ ] æ·»åŠ  gRPC æ”¯æŒ
- [ ] å®ç°è¯·æ±‚æ‰¹å¤„ç†
- [ ] æ·»åŠ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

## ğŸ“„ è®¸å¯è¯

Apache License 2.0 - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ”— é“¾æ¥

- GitHub: https://github.com/yourusername/Server_OpenSource
- é—®é¢˜åé¦ˆ: https://github.com/yourusername/Server_OpenSource/issues
- è®¨è®º: https://github.com/yourusername/Server_OpenSource/discussions

## ğŸ“ æ”¯æŒ

- æäº¤ issue æŠ¥å‘Š bug
- å‘èµ·è®¨è®ºæé—®
- å…ˆæŸ¥çœ‹æ–‡æ¡£

## ğŸ“ å­¦ä¹ æ›´å¤š

1. é˜…è¯» [README_CN.md](README_CN.md) äº†è§£æ¦‚è§ˆ
2. æŒ‰ç…§[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)è¿è¡Œ
3. æŸ¥çœ‹ [example_usage.py](example_usage.py) å­¦ä¹ ç¤ºä¾‹
4. é˜…è¯» [DEVELOPMENT_CN.md](DEVELOPMENT_CN.md) äº†è§£è‡ªå®šä¹‰
5. è¿è¡Œ [benchmark.py](benchmark.py) æµ‹è¯•æ€§èƒ½

## âœ… ç”¨æˆ·æ£€æŸ¥æ¸…å•

- [ ] å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`
- [ ] å‡†å¤‡ä½ çš„æ¨¡å‹
- [ ] åœ¨ server.py ä¸­è‡ªå®šä¹‰ `load_model()` å’Œ `model_inference()`
- [ ] å¯åŠ¨æœåŠ¡å™¨ï¼š`python server.py --model-path /path/to/model`
- [ ] æµ‹è¯•ï¼š`python test_server.py`
- [ ] é›†æˆåˆ°ä½ çš„åº”ç”¨

## ğŸŒŸ ä¸ºä»€ä¹ˆä½¿ç”¨è¿™ä¸ªï¼Ÿ

1. **å¿«é€Ÿ**ï¼šå¯¹äº numpy æ•°ç»„æ¯” JSON å¿« 10-50 å€
2. **ç®€å•**ï¼šæ˜“äºé›†æˆå’Œè‡ªå®šä¹‰
3. **çµæ´»**ï¼šæ”¯æŒä»»æ„ Python å¯¹è±¡
4. **å¥å£®**ï¼šè‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
5. **ç”Ÿäº§å°±ç»ª**ï¼šDocker æ”¯æŒï¼Œå®Œæ•´æ–‡æ¡£

---

**ç¥ç¼–ç æ„‰å¿«ï¼ğŸš€**
